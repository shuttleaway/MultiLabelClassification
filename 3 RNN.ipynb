{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataType = 'beauty'\n",
    "dataCol = 'Benefits'\n",
    "#Beauty ['Benefits', 'Brand', 'Colour_group', 'Product_texture', 'Skin_type']\n",
    "#Fashion ['Pattern', 'Collar Type', 'Fashion Trend', 'Clothing Material', 'Sleeves']\n",
    "\n",
    "MAIN_DIR=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data files\n",
    "json_mobile=MAIN_DIR+'data_full/mobile_profile_train.json'\n",
    "json_fashion=MAIN_DIR+'data_full/fashion_profile_train.json'\n",
    "json_beauty=MAIN_DIR+'data_full/beauty_profile_train.json'\n",
    "train_mobile=MAIN_DIR+'data_full/mobile_data_info_train_competition.csv'\n",
    "train_fashion=MAIN_DIR+'data_full/fashion_data_info_train_competition.csv'\n",
    "train_beauty=MAIN_DIR+'data_full/beauty_data_info_train_competition.csv'\n",
    "val_mobile=MAIN_DIR+'data_full/mobile_data_info_val_competition.csv'\n",
    "val_fashion=MAIN_DIR+'data_full/fashion_data_info_val_competition.csv'\n",
    "val_beauty=MAIN_DIR+'data_full/beauty_data_info_val_competition.csv'\n",
    "\n",
    "files_dict={'mobile':[json_mobile,train_mobile,val_mobile],'fashion':[json_fashion,train_fashion,val_fashion],'beauty':[json_beauty,train_beauty,val_beauty]}\n",
    "#files = [json_fashion,train_fashion,val_fashion]\n",
    "#files = [json_mobile,train_mobile,val_mobile]\n",
    "#files = [json_beauty,train_beauty,val_beauty]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_json(data,filename):\n",
    "    print(\"\")\n",
    "    \n",
    "def read_json(filename):\n",
    "    if filename:\n",
    "        with open(filename, 'r') as f:\n",
    "            datastore = json.load(f)\n",
    "    \n",
    "    return datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "SPECIAL_WORDS = {'PADDING': '<PAD>'}\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load Dataset from File\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(dataset_path, token_lookup, create_lookup_tables):\n",
    "    \"\"\"\n",
    "    Preprocess Text Data\n",
    "    \"\"\"\n",
    "    text = load_data(dataset_path)\n",
    "    \n",
    "    # Ignore notice, since we don't use it for analysing the data\n",
    "    #text = text[81:]\n",
    "\n",
    "    token_dict = token_lookup()\n",
    "    for key, token in token_dict.items():\n",
    "        text = text.replace(key, ' {} '.format(token))\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "\n",
    "    vocab_to_int, int_to_vocab = create_lookup_tables(text + list(SPECIAL_WORDS.values()))\n",
    "    int_text = [vocab_to_int[word] for word in text]\n",
    "    pickle.dump((int_text, vocab_to_int, int_to_vocab, token_dict), open('preprocess.p', 'wb'))\n",
    "\n",
    "\n",
    "def load_preprocess():\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    return pickle.load(open('preprocess.p', mode='rb'))\n",
    "\n",
    "\n",
    "def save_model(filename, decoder):\n",
    "    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n",
    "    torch.save(decoder, save_filename)\n",
    "\n",
    "\n",
    "def load_model(filename):\n",
    "    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n",
    "    return torch.load(save_filename,map_location=lambda storage, loc: storage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "      <th>image_path</th>\n",
       "      <th>Benefits</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Colour_group</th>\n",
       "      <th>Product_texture</th>\n",
       "      <th>Skin_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307504</td>\n",
       "      <td>nyx sex bomb pallete natural palette</td>\n",
       "      <td>beauty_image/6b2e9cbb279ac95703348368aa65da09.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461203</td>\n",
       "      <td>etude house precious mineral any cushion pearl...</td>\n",
       "      <td>beauty_image/20450222d857c9571ba8fa23bdedc8c9.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3592295</td>\n",
       "      <td>milani rose powder blush</td>\n",
       "      <td>beauty_image/6a5962bed605a3dd6604ca3a4278a4f9.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>393.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4460167</td>\n",
       "      <td>etude house baby sweet sugar powder</td>\n",
       "      <td>beauty_image/56987ae186e8a8e71fcc5a261ca485da.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5853995</td>\n",
       "      <td>bedak revlon color stay aqua mineral make up</td>\n",
       "      <td>beauty_image/9c6968066ebab57588c2f757a240d8b9.jpg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    itemid                                              title  \\\n",
       "0   307504               nyx sex bomb pallete natural palette   \n",
       "1   461203  etude house precious mineral any cushion pearl...   \n",
       "2  3592295                           milani rose powder blush   \n",
       "3  4460167                etude house baby sweet sugar powder   \n",
       "4  5853995       bedak revlon color stay aqua mineral make up   \n",
       "\n",
       "                                          image_path  Benefits  Brand  \\\n",
       "0  beauty_image/6b2e9cbb279ac95703348368aa65da09.jpg       1.0  157.0   \n",
       "1  beauty_image/20450222d857c9571ba8fa23bdedc8c9.jpg       NaN   73.0   \n",
       "2  beauty_image/6a5962bed605a3dd6604ca3a4278a4f9.jpg       NaN  393.0   \n",
       "3  beauty_image/56987ae186e8a8e71fcc5a261ca485da.jpg       NaN   73.0   \n",
       "4  beauty_image/9c6968066ebab57588c2f757a240d8b9.jpg       3.0   47.0   \n",
       "\n",
       "   Colour_group  Product_texture  Skin_type  \n",
       "0           NaN              NaN        NaN  \n",
       "1          11.0              7.0        NaN  \n",
       "2          20.0              6.0        NaN  \n",
       "3           NaN              6.0        NaN  \n",
       "4           NaN              6.0        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(files_dict[dataType][1])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286583 entries, 0 to 286582\n",
      "Data columns (total 8 columns):\n",
      "itemid             286583 non-null int64\n",
      "title              286583 non-null object\n",
      "image_path         286583 non-null object\n",
      "Benefits           113556 non-null float64\n",
      "Brand              238128 non-null float64\n",
      "Colour_group       121324 non-null float64\n",
      "Product_texture    244295 non-null float64\n",
      "Skin_type          58410 non-null float64\n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113556 entries, 0 to 113555\n",
      "Data columns (total 3 columns):\n",
      "itemid      113556 non-null int64\n",
      "title       113556 non-null object\n",
      "Benefits    113556 non-null float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df2 = df[['itemid','title',dataCol]]\n",
    "df2=df2.dropna()\n",
    "df2=df2.reset_index(drop=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "      <th>Benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307504</td>\n",
       "      <td>nyx sex bomb pallete natural palette</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5853995</td>\n",
       "      <td>bedak revlon color stay aqua mineral make up</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6208490</td>\n",
       "      <td>dr pure whitening cream</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9184082</td>\n",
       "      <td>sunprise all proof spf 50</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11425757</td>\n",
       "      <td>milani rose powder blush tea</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14954162</td>\n",
       "      <td>giordani gold age defying compact foundation d...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15584552</td>\n",
       "      <td>the body shop refill moisture white perfect fo...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16397989</td>\n",
       "      <td>lancome blush subtil long lasting powder blush...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19764106</td>\n",
       "      <td>cream dr biru original</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22836092</td>\n",
       "      <td>make over cleansing cream</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     itemid                                              title  Benefits\n",
       "0    307504               nyx sex bomb pallete natural palette       1.0\n",
       "1   5853995       bedak revlon color stay aqua mineral make up       3.0\n",
       "2   6208490                            dr pure whitening cream       6.0\n",
       "3   9184082                          sunprise all proof spf 50       6.0\n",
       "4  11425757                       milani rose powder blush tea       1.0\n",
       "5  14954162  giordani gold age defying compact foundation d...       6.0\n",
       "6  15584552  the body shop refill moisture white perfect fo...       6.0\n",
       "7  16397989  lancome blush subtil long lasting powder blush...       1.0\n",
       "8  19764106                             cream dr biru original       6.0\n",
       "9  22836092                          make over cleansing cream       3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['high pigmentation', 'natural', 'light', 'hydrating', 'durable', 'oil control', 'spf']\n"
     ]
    }
   ],
   "source": [
    "categories = read_json(files_dict[dataType][0])\n",
    "#print(categories.keys())\n",
    "#print(categories.values())\n",
    "classes=list(categories[dataCol].keys())\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 nyx sex bomb pallete natural palette\n",
       "1    etude house precious mineral any cushion pearl...\n",
       "2                             milani rose powder blush\n",
       "3                  etude house baby sweet sugar powder\n",
       "4         bedak revlon color stay aqua mineral make up\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'].to_csv(dataType+'_title.txt',header=None,index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "\n",
    "    counts = Counter(text)\n",
    "    vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(vocab)}\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "    \n",
    "    # return tuple\n",
    "    return (vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenized dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    dict = {\n",
    "        #\".\" : \"<PERIOD>\",\n",
    "        \",\" : \"<COMMA>\",\n",
    "        '\"' : \"<QUOTATION_MARK>\",\n",
    "        \";\" : \"<SEMICOLON>\",\n",
    "        \"!\" : \"<EXCLAMATION_MARK>\",\n",
    "        \"?\" : \"<QUESTION_MARK>\",\n",
    "        \"(\" : \"<LEFT_PAREN>\",\n",
    "        \")\" : \"<RIGHT_PAREN>\",\n",
    "        \"-\" : \"<DASH>\",\n",
    "        \"\\n\" : \"<RETURN>\"\n",
    "    }\n",
    "\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = MAIN_DIR+'data_full/beauty_title.txt'\n",
    "\n",
    "# pre-process training data\n",
    "preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_text, vocab_to_int, int_to_vocab, token_dict = load_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30977"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set equal length (around 3/4 between avg length and max length)\n",
    "pad = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 29 min 1 avg 8.121754905068865\n"
     ]
    }
   ],
   "source": [
    "#Number of words in title\n",
    "max_words = 0\n",
    "min_words = 100\n",
    "num_words = 0\n",
    "for sentence in df2.title:\n",
    "    temp = len(sentence.split())\n",
    "    if temp > max_words:\n",
    "        max_words = temp\n",
    "    if temp < min_words:\n",
    "        min_words = temp\n",
    "    num_words += temp\n",
    "avg = num_words/len(df2.title)\n",
    "print(\"max\",max_words,\"min\",min_words,\"avg\",avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44, 8382, 3002, 541, 14, 121, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr=[]\n",
    "for sentence in df2.title:\n",
    "    words = sentence.split()\n",
    "    #print(sentence)\n",
    "    temp= [vocab_to_int[word] for word in words]\n",
    "    if pad > len(temp):\n",
    "        padding = np.zeros(pad-len(temp)).astype(int)\n",
    "        temp.extend(padding)\n",
    "    arr.extend(temp[:pad])\n",
    "    #print(len(arr))\n",
    "arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2271120"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr) == pad*len(df2.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, arr, pad):\n",
    "        \n",
    "        self.itemid = dataframe.iloc[:,0]\n",
    "        self.labels = dataframe.iloc[:,-1]\n",
    "        self.data = arr\n",
    "        self.pad = pad        \n",
    "\n",
    "    def __len__(self):\n",
    "        #'Denotes the total number of samples'\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        'Generates one sample of data'\n",
    "        X = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        itemid = self.itemid[idx]\n",
    "\n",
    "        return X, y, itemid\n",
    "\n",
    "dataset = Dataset(df2, arr, pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2271120"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def batch_data(words, sequence_length, batch_size,target):\n",
    "    \"\"\"\n",
    "    Batch the neural network data using DataLoader\n",
    "    :param words: The word ids of the TV scripts\n",
    "    :param sequence_length: The sequence length of each batch\n",
    "    :param batch_size: The size of each batch; the number of sequences in a batch\n",
    "    :return: DataLoader with batched data\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    n_batches = len(words)//(batch_size*sequence_length)\n",
    "    words = words[:n_batches*(batch_size*sequence_length)] #cut short words to ensure full batches only\n",
    "    feature_tensors, target_tensors = [], []\n",
    "    \n",
    "    print(\"No. of batches: \",n_batches)\n",
    "    print(\"Batch size: \",batch_size)\n",
    "    \n",
    "    i=0\n",
    "    for idx in range(0, len(words), pad):     \n",
    "        batch_x = words[idx:idx+sequence_length]\n",
    "        #batch_y = words[idx+sequence_length]\n",
    "        feature_tensors.append(batch_x)\n",
    "        target_tensors.append(target[i])\n",
    "        i+=1\n",
    "    \n",
    "    feature_tensors = np.asarray(feature_tensors)\n",
    "    target_tensors = np.asarray(target_tensors)\n",
    "    print(feature_tensors.shape)\n",
    "    print(target_tensors.shape)\n",
    "    \n",
    "    data = TensorDataset(torch.LongTensor(feature_tensors), torch.LongTensor(target_tensors))\n",
    "    #data_loader = DataLoader(data, batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    # return a dataloader\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of batches:  2271\n",
      "Batch size:  50\n",
      "(113550, 20)\n",
      "(113550,)\n"
     ]
    }
   ],
   "source": [
    "target = df2.iloc[:,-1]\n",
    "dataset = batch_data(arr, pad, batch_size,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113556"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "num_workers = 0\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "train_indices = train_indices[:len(train_indices)-len(train_indices)%batch_size]\n",
    "test_indices = test_indices[:len(test_indices)-len(test_indices)%batch_size]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,num_workers=num_workers, sampler=test_sampler)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22700"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1816 454 2271\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader),len(test_loader),len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454.20000000000005"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)/batch_size*validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   15,    22,   124,    33,     4,     2,   270,    10,    56,    25,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  232,   661,    29,   435,   122,   862,    13,   149,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  380,  1131,  1096,     3,  2348,    10,  1854,   691,  1231,   819,\n",
       "           823,   205,    80,   178,     0,     0,     0,     0,     0,     0],\n",
       "        [   70,    42,    11,   175,     4,     2,    10,    79,   358,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   11,   177,     2,    10,    79,   137,   131,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   44,   196,     8,   412,   494,   502,     3,     9,     7,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  565,   294,     6,    74,    76,   760,  1625,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   89,   925,    28,   420,   435,     2,   145,   143,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  384,    29,   355,   281,    46,   311,     2,  1495,     4,   292,\n",
       "           358,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   89,   594,    61,     3,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  153,   487,     9,   729,   698,    10,   137,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   63,   186,     3,     7,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  147,    61,     3,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1442,   147,    14,   184,     3,   983,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 2667,    54,   232,  1550,  2019,    29,  1540,    32,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   70,    45,   247,   818,     6,    77,   262,    98,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   36,   164,   125,     2,    11,  3872,  2994,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  127,     6,    77,   326,    38,   760,   750,     7,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   41,   697,    62,     5,  1509,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   53,    15,    22,   513,   342,    46,     4,     5,    10,    56,\n",
       "            37,    48, 13261,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  594,  3103,  2865,   221,   274,  8502,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  332,   362,  2087,   285,     3,   221,    33,  1166,  1185,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   11,   747,    13,     3,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   67,    48,    69,    33,     3,   419,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  179,  3192,  1804,     4,  1607,    21,  1856,    36,     2,    18,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  147,    55,    75,   230,    13,     3,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  102,    16,  1743,   133,    35,     5,   316,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  650,    36,   610,  5190,   125,     2,   137,   131,    18,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   19,    40,  1956,  1226,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   16,   380,   444,   637,   427,    20,   143,  1528,     9,     7,\n",
       "            14,    50,    18,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  157,    55,    14,   577,   121,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  556,   450,   454,   627,     9,    10,    93,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  256,   263,     6,   127,   227,   126,    49,    81,   586,    83,\n",
       "             9,     3,   112,   130,     0,     0,     0,     0,     0,     0],\n",
       "        [  102,   133,   418,   218,    31,     2,    72,   105,   107,   125,\n",
       "           110,   766,    78,   104,     0,     0,     0,     0,     0,     0],\n",
       "        [   20,    70,   396,   881,   268,  2633,  1020,    10,   374,    17,\n",
       "          2502,  1252,  3417,   568,   514,     0,     0,     0,     0,     0],\n",
       "        [   41,   135,   107,    60,  2029, 10546,    10,   422,    25,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   52,   428,   720,    84,    83,    58,    10,    93,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  488,   489,    26,    13,     3,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  552,   389,    84,    83,    58,   301,    14,    71,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    2,  1724,   282,   356,   829,   280,    18,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   16,  1177,    62,   308,   729,   698,    10,    93,    70,    42,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   96,    18,    64,    30,     4,     3,  1278,  1018,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   80,  1080,   173,  1023,  1955,  2104,   686,     2,    10,    79,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  418,  1476,  1864,  1302,    62,    10,    79,    25,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 8335,   859,   478,    12,    40,    10,   291, 11378,  5729,    47,\n",
       "          3063,    42,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   16,    67,  1071,   198,     5,  1067,    25,    37,   737,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  153,   221,   659,  1105,   133,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   23,    94,   162,     3,  1253,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  182,   129,   573,     2,    23,    46,  2319,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [   64,     4,    30,     3,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test that it is loaded correctly\n",
    "dataiter = iter(test_loader)\n",
    "X,y= dataiter.next()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.3):\n",
    "        \"\"\"\n",
    "        Initialize the PyTorch RNN Module\n",
    "        :param vocab_size: The number of input dimensions of the neural network (the size of the vocabulary)\n",
    "        :param output_size: The number of output dimensions of the neural network\n",
    "        :param embedding_dim: The size of embeddings, should you choose to use them        \n",
    "        :param hidden_dim: The size of the hidden layer outputs\n",
    "        :param dropout: dropout to add in between LSTM/GRU layers\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        # TODO: Implement function\n",
    "        \n",
    "        # set class variables\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # define model layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, nn_input, hidden):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param nn_input: The input to the neural network\n",
    "        :param hidden: The hidden state        \n",
    "        :return: Two Tensors, the output of the neural network and the latest hidden state\n",
    "        \"\"\"\n",
    "        # TODO: Implement function   \n",
    "        #print('nn_input',nn_input)\n",
    "        batch_size = nn_input.size(0)\n",
    "        embeds = self.embedding(nn_input)\n",
    "        #print('hidden',hidden)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function - cross entropy loss used, maybe dont need sigmoid function\n",
    "        # sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = out.view(batch_size, -1, self.output_size)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "      \n",
    "        # return one batch of output word scores and the hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        '''\n",
    "        Initialize the hidden state of an LSTM/GRU\n",
    "        :param batch_size: The batch_size of the hidden state\n",
    "        :return: hidden state of dims (n_layers, batch_size, hidden_dim)\n",
    "        '''\n",
    "        # Implement function\n",
    "        \n",
    "        # initialize hidden state with zero weights, and move to GPU if available\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "\n",
    "def forward_back_prop(rnn, optimizer, criterion, inp, target, hidden):\n",
    "    \"\"\"\n",
    "    Forward and backward propagation on the neural network\n",
    "    :param decoder: The PyTorch Module that holds the neural network\n",
    "    :param decoder_optimizer: The PyTorch optimizer for the neural network\n",
    "    :param criterion: The PyTorch loss function\n",
    "    :param inp: A batch of input to the neural network\n",
    "    :param target: The target output for the batch of input\n",
    "    :return: The loss and the latest hidden state Tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    # move data to GPU, if available\n",
    "    if(train_on_gpu):\n",
    "        rnn.cuda()\n",
    "        inp, target = inp.cuda(), target.cuda()\n",
    "\n",
    "    rnn.train()\n",
    "    \n",
    "    # perform backpropagation and optimization\n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    h = tuple([each.data for each in hidden])\n",
    "    \n",
    "    #print('inp ',inp.shape)\n",
    "    #print('h ',h)\n",
    "    output, h = rnn(inp, h)\n",
    "    \n",
    "    loss = criterion(output, target)\n",
    "    #loss = criterion(output.squeeze(), target)\n",
    "    #print(\"output\",output.size())\n",
    "    #print(\"target\",target.size())\n",
    "    loss.backward()\n",
    "    \n",
    "    # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "    nn.utils.clip_grad_norm_(rnn.parameters(), 5)\n",
    "    \n",
    "    optimizer.step()    \n",
    "    \n",
    "    # return the loss over a batch and the hidden state produced by our model\n",
    "    return loss.item(), h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check for a GPU\n",
    "#train_on_gpu=False\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('No GPU found. Please use a GPU to train your neural network.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "vocab_size = len(vocab_to_int)\n",
    "output_size = len(classes)\n",
    "embedding_dim = len(vocab_to_int)//10\n",
    "hidden_dim = 256\n",
    "n_layers = 3\n",
    "\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113550"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
    "    batch_losses = []\n",
    "    \n",
    "    rnn.train()\n",
    "\n",
    "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
    "    for epoch_i in range(1, n_epochs + 1):\n",
    "        # initialize hidden state\n",
    "        hidden = rnn.init_hidden(batch_size)\n",
    "        start = time.time()\n",
    "        for batch_i, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # make sure you iterate over completely full batches, only\n",
    "            n_batches = len(train_loader.dataset)//batch_size\n",
    "            if(batch_i > n_batches):\n",
    "                break\n",
    "            \n",
    "            # forward, back prop\n",
    "            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)          \n",
    "            # record loss\n",
    "            batch_losses.append(loss)\n",
    "\n",
    "            # printing loss stats\n",
    "            if batch_i % show_every_n_batches == 0:\n",
    "                print('Epoch: {:>4}/{:<4}  Batch: {}  Loss: {}'.format(\n",
    "                    epoch_i, n_epochs, batch_i, np.average(batch_losses)))\n",
    "                batch_losses = []\n",
    "            \n",
    "        end = time.time()\n",
    "        print(\"Batch: \",batch_i, \"Time taken:\", end - start)\n",
    "            \n",
    "    # returns a trained rnn\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu\n",
      "Training for 5 epoch(s)...\n",
      "Epoch:    1/5     Batch: 0  Loss: 1.945650577545166\n",
      "Epoch:    1/5     Batch: 200  Loss: 1.1336316707730294\n",
      "Epoch:    1/5     Batch: 400  Loss: 0.699049841761589\n",
      "Epoch:    1/5     Batch: 600  Loss: 0.5819503055512905\n",
      "Epoch:    1/5     Batch: 800  Loss: 0.5377893857657909\n",
      "Epoch:    1/5     Batch: 1000  Loss: 0.4789429884403944\n",
      "Epoch:    1/5     Batch: 1200  Loss: 0.4810584168881178\n",
      "Epoch:    1/5     Batch: 1400  Loss: 0.4440986513346434\n",
      "Epoch:    1/5     Batch: 1600  Loss: 0.437048032656312\n",
      "Epoch:    1/5     Batch: 1800  Loss: 0.4450546015053988\n",
      "Batch:  1815 Time taken: 125.61521244049072\n",
      "Epoch:    2/5     Batch: 0  Loss: 0.43425910733640194\n",
      "Epoch:    2/5     Batch: 200  Loss: 0.36346681989729407\n",
      "Epoch:    2/5     Batch: 400  Loss: 0.3696157050132751\n",
      "Epoch:    2/5     Batch: 600  Loss: 0.3851727339625359\n",
      "Epoch:    2/5     Batch: 800  Loss: 0.37698832374066116\n",
      "Epoch:    2/5     Batch: 1000  Loss: 0.38326532069593666\n",
      "Epoch:    2/5     Batch: 1200  Loss: 0.3759563161060214\n",
      "Epoch:    2/5     Batch: 1400  Loss: 0.36842311747372153\n",
      "Epoch:    2/5     Batch: 1600  Loss: 0.3625161216035485\n",
      "Epoch:    2/5     Batch: 1800  Loss: 0.3810826962813735\n",
      "Batch:  1815 Time taken: 124.71759033203125\n",
      "Epoch:    3/5     Batch: 0  Loss: 0.37221965892240405\n",
      "Epoch:    3/5     Batch: 200  Loss: 0.30008154425770045\n",
      "Epoch:    3/5     Batch: 400  Loss: 0.3219192175939679\n",
      "Epoch:    3/5     Batch: 600  Loss: 0.32561181324534116\n",
      "Epoch:    3/5     Batch: 800  Loss: 0.32122907355427743\n",
      "Epoch:    3/5     Batch: 1000  Loss: 0.3211130641773343\n",
      "Epoch:    3/5     Batch: 1200  Loss: 0.3305688297003508\n",
      "Epoch:    3/5     Batch: 1400  Loss: 0.3334200155735016\n",
      "Epoch:    3/5     Batch: 1600  Loss: 0.3218043975159526\n",
      "Epoch:    3/5     Batch: 1800  Loss: 0.33003114476799966\n",
      "Batch:  1815 Time taken: 126.0070869922638\n",
      "Epoch:    4/5     Batch: 0  Loss: 0.31227382412180305\n",
      "Epoch:    4/5     Batch: 200  Loss: 0.285961125921458\n",
      "Epoch:    4/5     Batch: 400  Loss: 0.2930843724682927\n",
      "Epoch:    4/5     Batch: 600  Loss: 0.29513030499219894\n",
      "Epoch:    4/5     Batch: 800  Loss: 0.2962474745884538\n",
      "Epoch:    4/5     Batch: 1000  Loss: 0.2932254296541214\n",
      "Epoch:    4/5     Batch: 1200  Loss: 0.3029736075922847\n",
      "Epoch:    4/5     Batch: 1400  Loss: 0.29722723722457883\n",
      "Epoch:    4/5     Batch: 1600  Loss: 0.29825182490050794\n",
      "Epoch:    4/5     Batch: 1800  Loss: 0.30689597155898807\n",
      "Batch:  1815 Time taken: 126.30501437187195\n",
      "Epoch:    5/5     Batch: 0  Loss: 0.35189917031675577\n",
      "Epoch:    5/5     Batch: 200  Loss: 0.28429420363157987\n",
      "Epoch:    5/5     Batch: 400  Loss: 0.2752413671463728\n",
      "Epoch:    5/5     Batch: 600  Loss: 0.27909615349024536\n",
      "Epoch:    5/5     Batch: 800  Loss: 0.2784998277574778\n",
      "Epoch:    5/5     Batch: 1000  Loss: 0.2707124951481819\n",
      "Epoch:    5/5     Batch: 1200  Loss: 0.279227427393198\n",
      "Epoch:    5/5     Batch: 1400  Loss: 0.28303340304642916\n",
      "Epoch:    5/5     Batch: 1600  Loss: 0.2837376609072089\n",
      "Epoch:    5/5     Batch: 1800  Loss: 0.27834274955093863\n",
      "Batch:  1815 Time taken: 125.30132818222046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cwmkw\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "# create model and move to gpu if available\n",
    "rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
    "\n",
    "if train_on_gpu:\n",
    "    print('training on gpu')\n",
    "    rnn.cuda()\n",
    "    #rnn.cpu()\n",
    "\n",
    "# defining loss and optimization functions for training\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# training the model\n",
    "trained_rnn = train_rnn(rnn, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)\n",
    "\n",
    "# saving the trained model\n",
    "save_model('./save/trained_rnn_'+dataType, trained_rnn)\n",
    "print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "import os\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = load_preprocess()\n",
    "\n",
    "filename = './save/trained_rnn_'+dataType\n",
    "save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n",
    "\n",
    "rnn = torch.load(save_filename, map_location=lambda storage, loc: storage)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#helper.load_model('./save/trained_rnn2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "show_every=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "def test_rnn(test_loader,rnn,criterion,batch_size):\n",
    "\n",
    "    if train_on_gpu:\n",
    "        print('training on gpu')\n",
    "        rnn.cuda()\n",
    "\n",
    "    rnn.eval()\n",
    "    results=[]\n",
    "    correct=[]\n",
    "    end = time.time()\n",
    "    #start = time.time()\n",
    "    for batch_i, (inputs, labels) in enumerate(test_loader):\n",
    "        \n",
    "        total_batches = len(test_loader)\n",
    "        \n",
    "        hidden = rnn.init_hidden(batch_size)\n",
    "        output,_ = rnn(inputs,hidden)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # get the next word probabilities\n",
    "        p = F.softmax(output, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "        #_, indices = p.max(1)\n",
    "        \n",
    "        top_k = 3\n",
    "        p, top_i = p.topk(top_k)\n",
    "        top_i = top_i.numpy().squeeze()\n",
    "        \n",
    "        temp = top_i[:,0]==y.numpy().squeeze()\n",
    "        \n",
    "        if batch_i == 0:\n",
    "            results = top_i\n",
    "            correct = temp\n",
    "        else:\n",
    "            results = np.vstack((results,top_i))\n",
    "            correct = np.vstack((correct,temp))\n",
    "        \n",
    "        acc = correct.sum()/len(correct)/batch_size*100\n",
    "        \n",
    "        if batch_i % show_every == 0:\n",
    "                print('Batch: {:>4}/{:<4}  Batch: {}  Accuracy: {}'.format(\n",
    "                    batch_i, total_batches, batch_i, acc))\n",
    "        \n",
    "    \n",
    "    # returns a trained rnn\n",
    "    return {'results': results, 'num_correct': correct, 'loss': loss, 'accuracy': acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input and hidden tensors are not at the same device, found input tensor at cpu and hidden tensor at cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-a71f16fa15e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-9a28605c673d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, nn_input, hidden)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0membeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m#print('hidden',hidden)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# stack up lstm outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input and hidden tensors are not at the same device, found input tensor at cpu and hidden tensor at cuda:0"
     ]
    }
   ],
   "source": [
    "#test that the function is working\n",
    "dataiter = iter(test_loader)\n",
    "X,y= dataiter.next()\n",
    "hidden = rnn.init_hidden(batch_size)\n",
    "output,_=rnn(X,hidden)\n",
    "p = F.softmax(output, dim=1).data\n",
    "_, top_i = p.topk(3)\n",
    "top_i = top_i.numpy().squeeze()\n",
    "#print(top_i,labels)\n",
    "top_i[0:5,0]==y.numpy().squeeze()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_rnn(test_loader,rnn,criterion,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.110132158590307"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy\n",
    "test['num_correct'].sum()/len(correct)/batch_size*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 1, 3],\n",
       "       [6, 1, 3],\n",
       "       [4, 3, 1],\n",
       "       ...,\n",
       "       [4, 1, 3],\n",
       "       [3, 4, 1],\n",
       "       [4, 1, 3]], dtype=int64)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['results'][:,1]=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    num_epochs = 5\n",
    "    learning_rate = 0.001\n",
    "    vocab_size = len(vocab_to_int)\n",
    "    output_size = len(classes)\n",
    "    embedding_dim = len(vocab_to_int)//10\n",
    "    hidden_dim = 256\n",
    "    n_layers = 3\n",
    "    \n",
    "    Training for 5 epoch(s)...\n",
    "    Epoch:    1/5     Batch: 0  Loss: 1.945650577545166\n",
    "    Epoch:    1/5     Batch: 200  Loss: 1.1336316707730294\n",
    "    Epoch:    1/5     Batch: 400  Loss: 0.699049841761589\n",
    "    Epoch:    1/5     Batch: 600  Loss: 0.5819503055512905\n",
    "    Epoch:    1/5     Batch: 800  Loss: 0.5377893857657909\n",
    "    Epoch:    1/5     Batch: 1000  Loss: 0.4789429884403944\n",
    "    Epoch:    1/5     Batch: 1200  Loss: 0.4810584168881178\n",
    "    Epoch:    1/5     Batch: 1400  Loss: 0.4440986513346434\n",
    "    Epoch:    1/5     Batch: 1600  Loss: 0.437048032656312\n",
    "    Epoch:    1/5     Batch: 1800  Loss: 0.4450546015053988\n",
    "    Batch:  1815 Time taken: 125.61521244049072\n",
    "    Epoch:    2/5     Batch: 0  Loss: 0.43425910733640194\n",
    "    Epoch:    2/5     Batch: 200  Loss: 0.36346681989729407\n",
    "    Epoch:    2/5     Batch: 400  Loss: 0.3696157050132751\n",
    "    Epoch:    2/5     Batch: 600  Loss: 0.3851727339625359\n",
    "    Epoch:    2/5     Batch: 800  Loss: 0.37698832374066116\n",
    "    Epoch:    2/5     Batch: 1000  Loss: 0.38326532069593666\n",
    "    Epoch:    2/5     Batch: 1200  Loss: 0.3759563161060214\n",
    "    Epoch:    2/5     Batch: 1400  Loss: 0.36842311747372153\n",
    "    Epoch:    2/5     Batch: 1600  Loss: 0.3625161216035485\n",
    "    Epoch:    2/5     Batch: 1800  Loss: 0.3810826962813735\n",
    "    Batch:  1815 Time taken: 124.71759033203125\n",
    "    Epoch:    3/5     Batch: 0  Loss: 0.37221965892240405\n",
    "    Epoch:    3/5     Batch: 200  Loss: 0.30008154425770045\n",
    "    Epoch:    3/5     Batch: 400  Loss: 0.3219192175939679\n",
    "    Epoch:    3/5     Batch: 600  Loss: 0.32561181324534116\n",
    "    Epoch:    3/5     Batch: 800  Loss: 0.32122907355427743\n",
    "    Epoch:    3/5     Batch: 1000  Loss: 0.3211130641773343\n",
    "    Epoch:    3/5     Batch: 1200  Loss: 0.3305688297003508\n",
    "    Epoch:    3/5     Batch: 1400  Loss: 0.3334200155735016\n",
    "    Epoch:    3/5     Batch: 1600  Loss: 0.3218043975159526\n",
    "    Epoch:    3/5     Batch: 1800  Loss: 0.33003114476799966\n",
    "    Batch:  1815 Time taken: 126.0070869922638\n",
    "    Epoch:    4/5     Batch: 0  Loss: 0.31227382412180305\n",
    "    Epoch:    4/5     Batch: 200  Loss: 0.285961125921458\n",
    "    Epoch:    4/5     Batch: 400  Loss: 0.2930843724682927\n",
    "    Epoch:    4/5     Batch: 600  Loss: 0.29513030499219894\n",
    "    Epoch:    4/5     Batch: 800  Loss: 0.2962474745884538\n",
    "    Epoch:    4/5     Batch: 1000  Loss: 0.2932254296541214\n",
    "    Epoch:    4/5     Batch: 1200  Loss: 0.3029736075922847\n",
    "    Epoch:    4/5     Batch: 1400  Loss: 0.29722723722457883\n",
    "    Epoch:    4/5     Batch: 1600  Loss: 0.29825182490050794\n",
    "    Epoch:    4/5     Batch: 1800  Loss: 0.30689597155898807\n",
    "    Batch:  1815 Time taken: 126.30501437187195\n",
    "    Epoch:    5/5     Batch: 0  Loss: 0.35189917031675577\n",
    "    Epoch:    5/5     Batch: 200  Loss: 0.28429420363157987\n",
    "    Epoch:    5/5     Batch: 400  Loss: 0.2752413671463728\n",
    "    Epoch:    5/5     Batch: 600  Loss: 0.27909615349024536\n",
    "    Epoch:    5/5     Batch: 800  Loss: 0.2784998277574778\n",
    "    Epoch:    5/5     Batch: 1000  Loss: 0.2707124951481819\n",
    "    Epoch:    5/5     Batch: 1200  Loss: 0.279227427393198\n",
    "    Epoch:    5/5     Batch: 1400  Loss: 0.28303340304642916\n",
    "    Epoch:    5/5     Batch: 1600  Loss: 0.2837376609072089\n",
    "    Epoch:    5/5     Batch: 1800  Loss: 0.27834274955093863\n",
    "    Batch:  1815 Time taken: 125.30132818222046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    num_epochs = 3\n",
    "    learning_rate = 0.001\n",
    "    vocab_size = len(vocab_to_int)\n",
    "    output_size = len(classes)\n",
    "    embedding_dim = len(vocab_to_int)//10\n",
    "    hidden_dim = 256\n",
    "    n_layers = 1\n",
    "\n",
    "accuracy = 24.110132158590307\n",
    "\n",
    "    training on gpu\n",
    "    Training for 3 epoch(s)...\n",
    "    Epoch:    1/3     Batch: 0  Loss: 1.948210597038269\n",
    "    Epoch:    1/3     Batch: 100  Loss: 1.2629362106323243\n",
    "    Epoch:    1/3     Batch: 200  Loss: 0.9147671985626221\n",
    "    Epoch:    1/3     Batch: 300  Loss: 0.7619446340203285\n",
    "    Epoch:    1/3     Batch: 400  Loss: 0.6443701910972596\n",
    "    Epoch:    1/3     Batch: 500  Loss: 0.5483935502171516\n",
    "    Epoch:    1/3     Batch: 600  Loss: 0.5587578392028809\n",
    "    Epoch:    1/3     Batch: 700  Loss: 0.5181590831279754\n",
    "    Epoch:    1/3     Batch: 800  Loss: 0.5057365174591542\n",
    "    Epoch:    1/3     Batch: 900  Loss: 0.4920829881727695\n",
    "    Epoch:    1/3     Batch: 1000  Loss: 0.4556227692961693\n",
    "    Epoch:    1/3     Batch: 1100  Loss: 0.47841481506824496\n",
    "    Epoch:    1/3     Batch: 1200  Loss: 0.44066833704710007\n",
    "    Epoch:    1/3     Batch: 1300  Loss: 0.45724679514765737\n",
    "    Epoch:    1/3     Batch: 1400  Loss: 0.43142399355769157\n",
    "    Epoch:    1/3     Batch: 1500  Loss: 0.4343838082253933\n",
    "    Epoch:    1/3     Batch: 1600  Loss: 0.4362485967576504\n",
    "    Epoch:    1/3     Batch: 1700  Loss: 0.43836094304919243\n",
    "    Epoch:    1/3     Batch: 1800  Loss: 0.41377399206161497\n",
    "    Batch:  1815 Time taken: 115.52667593955994\n",
    "    Epoch:    2/3     Batch: 0  Loss: 0.37961600814014673\n",
    "    Epoch:    2/3     Batch: 100  Loss: 0.37738112553954123\n",
    "    Epoch:    2/3     Batch: 200  Loss: 0.35926029592752456\n",
    "    Epoch:    2/3     Batch: 300  Loss: 0.3498434928059578\n",
    "    Epoch:    2/3     Batch: 400  Loss: 0.34742066502571106\n",
    "    Epoch:    2/3     Batch: 500  Loss: 0.3530371794104576\n",
    "    Epoch:    2/3     Batch: 600  Loss: 0.37153015077114104\n",
    "    Epoch:    2/3     Batch: 700  Loss: 0.34142743326723574\n",
    "    Epoch:    2/3     Batch: 800  Loss: 0.35123591259121895\n",
    "    Epoch:    2/3     Batch: 900  Loss: 0.35717400774359703\n",
    "    Epoch:    2/3     Batch: 1000  Loss: 0.3624216615408659\n",
    "    Epoch:    2/3     Batch: 1100  Loss: 0.3542009150981903\n",
    "    Epoch:    2/3     Batch: 1200  Loss: 0.3638387350738049\n",
    "    Epoch:    2/3     Batch: 1300  Loss: 0.35564811766147614\n",
    "    Epoch:    2/3     Batch: 1400  Loss: 0.3456290701031685\n",
    "    Epoch:    2/3     Batch: 1500  Loss: 0.35080010920763016\n",
    "    Epoch:    2/3     Batch: 1600  Loss: 0.36891542047262194\n",
    "    Epoch:    2/3     Batch: 1700  Loss: 0.35634012162685397\n",
    "    Epoch:    2/3     Batch: 1800  Loss: 0.3570907928049564\n",
    "    Batch:  1815 Time taken: 116.11233305931091\n",
    "    Epoch:    3/3     Batch: 0  Loss: 0.4040226051583886\n",
    "    Epoch:    3/3     Batch: 100  Loss: 0.2952263676375151\n",
    "    Epoch:    3/3     Batch: 200  Loss: 0.30173510633409023\n",
    "    Epoch:    3/3     Batch: 300  Loss: 0.30685905784368517\n",
    "    Epoch:    3/3     Batch: 400  Loss: 0.3028623998910189\n",
    "    Epoch:    3/3     Batch: 500  Loss: 0.30551651425659654\n",
    "    Epoch:    3/3     Batch: 600  Loss: 0.3014995303750038\n",
    "    Epoch:    3/3     Batch: 700  Loss: 0.322334857955575\n",
    "    Epoch:    3/3     Batch: 800  Loss: 0.31686400577425955\n",
    "    Epoch:    3/3     Batch: 900  Loss: 0.3158319129794836\n",
    "    Epoch:    3/3     Batch: 1000  Loss: 0.3012016559392214\n",
    "    Epoch:    3/3     Batch: 1100  Loss: 0.31715072341263295\n",
    "    Epoch:    3/3     Batch: 1200  Loss: 0.31085215888917445\n",
    "    Epoch:    3/3     Batch: 1300  Loss: 0.2972731766849756\n",
    "    Epoch:    3/3     Batch: 1400  Loss: 0.30479449197649955\n",
    "    Epoch:    3/3     Batch: 1500  Loss: 0.30092962466180323\n",
    "    Epoch:    3/3     Batch: 1600  Loss: 0.31835667058825495\n",
    "    Epoch:    3/3     Batch: 1700  Loss: 0.32387007847428323\n",
    "    Epoch:    3/3     Batch: 1800  Loss: 0.32105328977108\n",
    "    Batch:  1815 Time taken: 115.94001650810242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_str(string):\n",
    "  \"\"\"\n",
    "  Tokenization/string cleaning for all datasets except for SST.\n",
    "  \"\"\"\n",
    "  string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "  string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "  string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "  string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "  string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "  string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "  string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "  string = re.sub(r\",\", \" , \", string)\n",
    "  string = re.sub(r\"!\", \" ! \", string)\n",
    "  string = re.sub(r\"\\(\", \" ( \", string)\n",
    "  string = re.sub(r\"\\)\", \" ) \", string)\n",
    "  string = re.sub(r\"\\?\", \" ? \", string)\n",
    "  string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "  return string.lower().strip().split()\n",
    "\n",
    "\n",
    "def clean_str_sst(string):\n",
    "  \"\"\"\n",
    "  Tokenization/string cleaning for the SST dataset\n",
    "  \"\"\"\n",
    "  string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "  string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "  return string.lower().strip().split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
